{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from module.prepare import *\n",
    "from itertools import product\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import sys\n",
    "from collections import Counter\n",
    "import random\n",
    "from itertools import islice\n",
    "import time\n",
    "import configparser\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import bokeh\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "\n",
    "import sklearn\n",
    "from joblib import dump, load\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.manifold import *\n",
    "import sklearn.tree as Tr \n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from module.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCurrentTime():\n",
    "    return datetime.datetime.strftime(datetime.datetime.fromtimestamp(time.time()),format='%Y-%m-%d-%H-%M-%S')\n",
    "\n",
    "\n",
    "def LGBTuning(Xtrain,Xtest,Ytrain,Ytest,new_params=None):\n",
    "    \n",
    "    clf = lgb.LGBMClassifier(objective='cross_entropy', ### {cross_entropy, binary}\n",
    "                             silent=False,\n",
    "                             verbose=1,\n",
    "                             random_state=seed,\n",
    "                             n_jobs=20,\n",
    "#                              class_weight\n",
    "                            )\n",
    "    \n",
    "    default_params = {\n",
    "    'learning_rate': [0.1], \n",
    "    'boosting_type':['gbdt'], \n",
    "    'n_estimators': [500],\n",
    "    'num_iterations':[1000],\n",
    "    'max_bin':[256]\n",
    "    }\n",
    "    \n",
    "    if new_params is not None:\n",
    "        default_params.update(new_params)\n",
    "    \n",
    "    arg_str = ''\n",
    "    for k,v in default_params.items():\n",
    "        if type(v[0])==str:\n",
    "            arg_str += k+'='+\"'\"+v[0]+\"',\"\n",
    "        else:\n",
    "            arg_str += k+'='+str(v[0])+\",\"\n",
    "    eval(\n",
    "        'clf.'+clf.set_params.__name__+\"(\"\n",
    "            +arg_str.rstrip(',')+\n",
    "            \")\"\n",
    "        )\n",
    "\n",
    "    print('DEBUG:: tuning params\\n',clf.get_params())\n",
    "    clf.fit(Xtrain,Ytrain)\n",
    "    Ypred = clf.predict(Xtest)\n",
    "    score_train = clf.score(Xtrain,Ytrain)\n",
    "    print('train score %f'%score_train)\n",
    "    \n",
    "    return [Ypred,Ytest,score_train,clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 5\n",
    "generalize_ratio = 1.0/cv\n",
    "test_ratio = 1.0/cv\n",
    "tuning_mode = False\n",
    "\n",
    "if tuning_mode:\n",
    "    cv = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tuning 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TuningParametersStage1(fname=getCurrentTime()+'-stage1.csv'):\n",
    "    res = []\n",
    "    for DATAID in [0,1,2,3,4,5]:\n",
    "        INFO('data id %d'%DATAID)\n",
    "        for RNA_K in range(3,7):\n",
    "            for PROTEIN_K in range(3,7):\n",
    "                for TOP_RATIO in np.linspace(0.93,0.99,5):\n",
    "                    start_time = time.time()\n",
    "                    [data,T] = ReadData(DATAID,PROTEIN_K,RNA_K)\n",
    "                    [X,Y] = ToMatrix(data,'dense')\n",
    "                    [X_train,X_test,Y_train,Y_test] = SplitDataset(X,Y,generalize_ratio)\n",
    "                    [X_train,X_test,Y_train,Y_test] = \\\n",
    "                                RandomForestDimensionalityReduction(X_train,X_test,Y_train,Y_test,topRatio=TOP_RATIO)\n",
    "                    r = LGBTuning(X_train,X_test,Y_train,Y_test)\n",
    "                    r = {\n",
    "                        'DATAID': DATAID,\n",
    "                        'test_score':scoreFunction(r[0],r[1]),\n",
    "                        'train_score':r[2],\n",
    "                        'RNA_K':RNA_K,\n",
    "                        'PROTEIN_K':PROTEIN_K,\n",
    "                        'TOP_RATIO':TOP_RATIO\n",
    "                    }\n",
    "                    print('DEBUG:: result ',r)\n",
    "                    res.append(r)\n",
    "                    end_time = time.time()\n",
    "                    print('DEBUG:: time elapsed ',(end_time-start_time)/60)\n",
    "    df = pd.DataFrame(data=res,columns=['DATAID','test_score','train_score','RNA_K','PROTEIN_K','TOP_RATIO'])\n",
    "    df.to_csv(os.path.join('./result',fname))\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TuningParametersStage1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# fname_optimal_stage1 = './result/2020-05-04-20-55-26-stage1.csv'\n",
    "# df = pd.read_csv(fname_optimal_stage1)\n",
    "# acc = [ float(re.findall('[0-9]+\\.[0-9]+',x)[0]) for x in df['test_score'] ]\n",
    "# auc = [ float(re.findall('[0-9]+\\.[0-9]+',x)[1]) for x in df['test_score'] ]\n",
    "# df['acc'] = acc\n",
    "# df['auc'] = auc\n",
    "\n",
    "# new_df1 = df.groupby(by=['DATAID','PROTEIN_K','RNA_K']).agg({'acc':np.max,'auc':np.max})\n",
    "# new_df2 = df.groupby(by=['DATAID','PROTEIN_K','RNA_K']).agg({'acc':np.mean,'auc':np.mean})\n",
    "\n",
    "params_1 = {\n",
    "    0:[(5,5,0.99)],\n",
    "    1:[(3,4,0.96),(3,3,0.99)],\n",
    "    2:[(6,6,0.96),(4,4,0.96)],\n",
    "    3:[(3,3,0.975),(6,3,0.96)],\n",
    "    4:[(4,3,0.96)],\n",
    "    5:[(4,6,0.945)]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_result2 = getCurrentTime()+'-stage2.csv'\n",
    "\n",
    "tune_grid = [\n",
    "    [{\n",
    "        'learning_rate': [0.1], ### 0.1\n",
    "        'boosting_type':['gbdt'], ### goss>gbdt\n",
    "        'n_estimators': [500],\n",
    "        'num_iterations':[1000,2000], ### 2000\n",
    "        'num_leaves': [200], ### <400<675\n",
    "        'max_bin':[256],\n",
    "        'colsample_bytree' : [0.7,0.75,0.8,0.85], ### 0.75\n",
    "        'subsample_freq':[1], ### 1\n",
    "        'lambda_l1': [1e-3,0]\n",
    "    }],\n",
    "    [{\n",
    "        'colsample_bytree': [1], \n",
    "        'lambda_l1': [0], \n",
    "        'learning_rate': [0.05], \n",
    "        'min_data_in_leaf': [12,13,14,15], \n",
    "        'num_iterations': [1000], \n",
    "        'num_leaves': [80,100,120,150,200]\n",
    "    }],\n",
    "    [{\n",
    "        'colsample_bytree': [0.7,0.8,0.85,0.9,0.95], \n",
    "        'lambda_l1': [0], # =\n",
    "        'learning_rate': [0.05,0.01,0.1], \n",
    "        'min_data_in_leaf': [20], # =\n",
    "        'num_iterations': [500,1000,2000],\n",
    "        'num_leaves': [50]\n",
    "     }],\n",
    "    [{\n",
    "        'colsample_bytree': [0.8,0.85,0.9,0.95],  \n",
    "        'lambda_l1': [0.001], \n",
    "        'learning_rate': [0.1,0.001,0.5],  \n",
    "        'max_depth': [3,4,6,-1], \n",
    "        'min_data_in_leaf': [10,18,30], \n",
    "        'num_iterations': [500,1000,2000], \n",
    "        'num_leaves': [10,40,60,80,100,120]\n",
    "     }],\n",
    "    [{\n",
    "        'colsample_bytree': [0.8,0.85,0.9,0.95],  \n",
    "        'lambda_l1': [0], \n",
    "        'learning_rate': [0.01,0.001,0.5], \n",
    "        'max_depth': [3,4,6,-1],  \n",
    "        'min_data_in_leaf': [10,18,30], \n",
    "        'num_iterations': [500,1000,2000], \n",
    "        'num_leaves': [10,40,60,80,100,120]\n",
    "     }],\n",
    "    [{\n",
    "        'colsample_bytree': [0.8,0.85,0.9,0.95],  \n",
    "        'lambda_l1': [0], \n",
    "        'learning_rate': [0.01,0.001,0.5], \n",
    "        'max_depth': [3,4,6,-1],  \n",
    "        'min_data_in_leaf': [10,18,30], \n",
    "        'num_iterations': [500,1000,2000], \n",
    "        'num_leaves': [10,40,60,80,100,120]\n",
    "     }]\n",
    "]\n",
    "\n",
    "tune_grid = list(map(lambda x:list(ParameterGrid(x)),tune_grid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": 2}'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps({'1':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO::dataid 0\n",
      "read data 5 5\n",
      "=============RETRIEVE TRIAN DATA=================\n",
      "# DEBUG: # DEBUG: **************new dl 0***************\n",
      "# DEBUG: READ SEQ FROM FILE\n",
      "# DEBUG: READ CLUSTER FROM FILE\n",
      "ERROR:: regex  \n",
      "ERROR:: regex  \n",
      "# DEBUG: READ PAIR FROM FILE\n",
      "read line error \n",
      "# DEBUG: GENERATE NEGATIVE PAIR\n",
      "# DEBUG: negative pair number 10411\n",
      "INFO::count of negative pairs10411\n",
      "# DEBUG: PAIR UNION\n",
      "# DEBUG: EXTRACT FEATURES--PROTEIN\n",
      "# DEBUG: EXTRACT FEATURES--RNA\n",
      "# DEBUG: K-MER CALCULATION\n",
      "# DEBUG: FEATURE UNION\n",
      "# DEBUG: GARBAGE COLLECTION\n",
      "MATRIX TRANSFORMATION\n",
      "DEBUG:: total features count  32068\n",
      "data shape 20822 32068\n",
      "rf raw data fit score 1.000000\n",
      "INFO::dimension remained 31907 0.990000\n",
      "dimension remained 31907\n",
      "INFO::tuning cv 0\n",
      "{'boosting_type': ['gbdt'], 'colsample_bytree': [0.7], 'lambda_l1': [0.001], 'learning_rate': [0.1], 'max_bin': [256], 'n_estimators': [500], 'num_iterations': [1000], 'num_leaves': [200], 'subsample_freq': [1]}\n",
      "DEBUG:: tuning params\n",
      " {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.7, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': 20, 'num_leaves': 200, 'objective': 'cross_entropy', 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': False, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 1, 'verbose': 1, 'num_iterations': 1000, 'max_bin': 256, 'lambda_l1': 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "tuning_cv2 = 1\n",
    "tuning_generalize_ratio2 = 1.0/tuning_cv2 if tuning_cv2!=1 else 0.2\n",
    "\n",
    "df_columns = ['dataid','protein_k','rna_k','top_ratio','training_score','tune_param','scores']\n",
    "df_result2 = pd.DataFrame([],columns=df_columns)\n",
    "\n",
    "for _dataid in [0,1,2,3,4,5]:\n",
    "    INFO('dataid %d'%_dataid)\n",
    "    for global_params in params_1[_dataid]:\n",
    "        ### get conf of dataid\n",
    "        protein_k = global_params[0]\n",
    "        rna_k = global_params[1]\n",
    "        top_ratio = global_params[2]\n",
    "        ### read data\n",
    "        [data,T] = ReadData(_dataid,protein_k,rna_k)\n",
    "        [X,Y] = ToMatrix(data,'dense')\n",
    "        ### split dataset\n",
    "        [X_train,X_test,Y_train,Y_test] = SplitDataset(X,Y,tuning_generalize_ratio2)\n",
    "        ### dimensionality reduction\n",
    "        [X_train,X_test,Y_train,Y_test] = \\\n",
    "                    RandomForestDimensionalityReduction(X_train,X_test,Y_train,Y_test,topRatio=top_ratio)\n",
    "        for _cv in range(tuning_cv2):\n",
    "            INFO('tuning cv %d'%_cv)\n",
    "            for sp in tune_grid[_dataid]:\n",
    "                sp = dict(map(lambda x:(x,[sp[x]]),sp))\n",
    "                print(sp)\n",
    "                tune_results = LGBTuning(X_train,X_test,Y_train,Y_test,sp)\n",
    "                tune_score = scoreFunction(tune_results[0],tune_results[1])\n",
    "                r = pd.Series({\n",
    "                                'dataid':_dataid,\n",
    "                                'protein_k':protein_k,\n",
    "                                'rna_k':rna_k,\n",
    "                                'top_ratio':top_ratio,\n",
    "                                'training_score':tune_results[2],\n",
    "                                'tune_param':json.dumps(sp),\n",
    "                                'scores':json.dumps(tune_score),\n",
    "                })\n",
    "                print(r)\n",
    "                break \n",
    "                df_result2 = df_result2.append(r,ignore_index=True)\n",
    "            \n",
    "df_result2.to_csv(fname_result2)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
