{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IDE_Project_Programming\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import gc\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "from itertools import islice\n",
    "import time\n",
    "from scipy.sparse import csr_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import bokeh\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "from sklearn.feature_selection import *\n",
    "import time\n",
    "from joblib import dump, load\n",
    "import configparser\n",
    "import json\n",
    "\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.ensemble import *\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import *\n",
    "\n",
    "import lightgbm as lgb\n",
    "import sklearn.tree as Tr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.module import *\n",
    "from module.process import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "DATASET = 2\n",
    "CONFIGURE_PATH = './conf.ini'\n",
    "\n",
    "def GetConfigure():\n",
    "    global PROTEIN_K,RNA_K,ENTROPY_IM,topK,RF_ENSENBLE,TRAIN_TEST_SPLIT\n",
    "    global cfile,conf,commons\n",
    "    global PARAMS\n",
    "    cfile = configparser.ConfigParser()\n",
    "    cfile.read(CONFIGURE_PATH)\n",
    "    conf = dict(cfile.items(str(DATASET)))\n",
    "    commons = dict(cfile.items('common'))\n",
    "\n",
    "    PROTEIN_K = int( conf[str.lower('PROTEIN_K')] )\n",
    "    RNA_K = int( conf[str.lower('RNA_K')] )\n",
    "    ENTROPY_IM = float( conf[str.lower('ENTROPY_IM')] )\n",
    "    topK = int( conf[str.lower('topK')] )\n",
    "    RF_ENSENBLE = int( conf[str.lower('RF_ENSENBLE')] )\n",
    "    TRAIN_TEST_SPLIT = float( commons[str.lower('TRAIN_TEST_SPLIT')] )\n",
    "    PARAMS = conf['params']\n",
    "    PARAMS = dict(eval(PARAMS))\n",
    "    return\n",
    "\n",
    "GetConfigure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadData():\n",
    "    T=trainer(5,-1)\n",
    "    data = T.MAIN_SINGLE_TEST(DATASET,PROTEIN_K,RNA_K)\n",
    "    return data,T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pair 文件输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "OutputPairToFile(T.pairs,'./pairs'\n",
    "                 +str(DATASET)\n",
    "                 +str(PROTEIN_K)\n",
    "                 +str(RNA_K)\n",
    "                 +'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToMatrix(data,matrix_type='sparse'):\n",
    "    res = Dict2Sparse(data)\n",
    "    print('data shape %d %d'%(res[3],res[4]))\n",
    "    arr = csr_matrix( ( np.array(res[2]),\n",
    "                 (np.array(res[0]), np.array(res[1])) \n",
    "                ), shape = (res[3],res[4]) )\n",
    "    if matrix_type=='dense':\n",
    "        arr = arr.todense() ### matrix\n",
    "        [X,Y] = [np.array(arr),np.array(data[0][1])]\n",
    "        return [X,Y]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MutualInformationFeatureSelection(arr,data):\n",
    "    mi = mutual_info_classif(arr,data[0][1],copy=False,n_neighbors=4)\n",
    "    select = mi>ENTROPY_IM\n",
    "    select = np.hstack([select,[False]])\n",
    "    X = DictionaryToMatrix(data[0][0],data[0][1],feature_num=data[1]+1,select=select)\n",
    "    Y = np.array(data[0][1])\n",
    "    print('dimension ratio %f dimension remained %d'\n",
    "          %(X.shape[1]/(data[1]+1),\n",
    "            X.shape[1]))\n",
    "    return [X,Y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据集分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitDataset(X,Y):\n",
    "    X_train, X_test, Y_train, Y_test = \\\n",
    "        train_test_split(X,Y,test_size=TRAIN_TEST_SPLIT,random_state = seed)\n",
    "    del X,Y\n",
    "    return [X_train,X_test,Y_train,Y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 二次降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForestDimensionalityReduction(X_train,X_test,Y_train,Y_test):\n",
    "    rfclf = RandomForestClassifier(n_estimators=RF_ENSENBLE,n_jobs=3)\n",
    "    rfclf.fit(X_train,Y_train)\n",
    "    rf_fit_score = rfclf.score(X_train,Y_train)\n",
    "    print('rf raw data fit score %f'%rf_fit_score)\n",
    "\n",
    "    rf_select = list(zip([i for i in range(len(rfclf.feature_importances_))],rfclf.feature_importances_))\n",
    "    rf_select = sorted(rf_select,key=lambda x:x[1],reverse=True)\n",
    "    rf_select = list(map(lambda x:[x[0],x[1]],rf_select))\n",
    "    rf_select = np.array(rf_select)\n",
    "\n",
    "    print('select top K features importances',sum(rf_select[:topK,1]))\n",
    "    rf_select = rf_select[:topK,0]\n",
    "    rf_select = rf_select.astype('int32')\n",
    "    X_train = X_train[:,rf_select]\n",
    "    X_test = X_test[:,rf_select]\n",
    "    print('dimension remained %d'%X_train.shape[1])\n",
    "    return [X_train,X_test,Y_train,Y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecisionTreePrefit(X_train,X_test,Y_train,Y_test):\n",
    "    dtc = Tr.DecisionTreeClassifier()\n",
    "    dtc.fit(X_train,Y_train)\n",
    "    print('pre fit score',dtc.score(X_train,Y_train))\n",
    "    print('pre test score',dtc.score(X_test,Y_test))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGBTuning(X_train,X_test,Y_train,Y_test):\n",
    "    params = {\n",
    "        \n",
    "            }\n",
    "    \n",
    "    clf = lgb.LGBMClassifier()\n",
    "    \n",
    "    \n",
    "    return params\n",
    "\n",
    "def LGBFit(X_train,X_test,Y_train,Y_test):\n",
    "    lgb_train = lgb.Dataset(X_train, Y_train)\n",
    "    lgb_test = lgb.Dataset(X_test, Y_test, reference=lgb_train)\n",
    "\n",
    "    params = {    \n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'binary',\n",
    "                'metric': 'acc',\n",
    "                'nthread':6,\n",
    "#                 'learning_rate':0.08,\n",
    "                'num_leaves':300, \n",
    "                'max_depth': -1,   \n",
    "                'subsample': 0.9, \n",
    "                'colsample_bytree': 0.9, \n",
    "                'feature_fraction': 1,\n",
    "                'bagging_freq': 8,\n",
    "#                 'num_iterations':300,\n",
    "                'min_data_in_leaf':2,\n",
    "                'bagging_fraction': 0.8,\n",
    "                'num_boost_round':3000,\n",
    "        \n",
    "            }\n",
    "\n",
    "    cv_results = lgb.cv(params, lgb_train, nfold=5  \n",
    "                        ,stratified=False, shuffle=True\n",
    "                        ,seed=seed,\n",
    "                        metrics=['auc','binary_logloss','mae']\n",
    "                        ,verbose_eval=1)\n",
    "    print('best n_estimators:', len(cv_results['auc-mean']))\n",
    "    for k,v in cv_results.items():\n",
    "        print('best cv score:', k, pd.Series(cv_results[k]).max())\n",
    "    return [lgb,cv_results]\n",
    "\n",
    "# lgbclf = lgb.LGBMClassifier(learning_rate=0.045,\n",
    "#                            max_depth=-1,\n",
    "#                            objective='binary',\n",
    "#                             num_leaves=1000,\n",
    "#                             min_child_samples=10,\n",
    "#                             n_estimators=1000,\n",
    "#                             subsample=0.9,\n",
    "#                             random_state=42\n",
    "#                            )\n",
    "# lgbclf.fit(X_train,Y_train)\n",
    "# print('train',lgbclf.score(X_train,Y_train))\n",
    "# print('test',lgbclf.score(X_test,Y_test))\n",
    "\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# Y_pred = lgb.predict(X_test, num_iteration=gbm.best_iteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pipeline():\n",
    "    T=trainer(5,-1)\n",
    "    data = T.MAIN_SINGLE_TEST(DATASET,PROTEIN_K,RNA_K)\n",
    "    OutputPairToFile(T.pairs,'./pairs'\n",
    "                     +str(DATASET)\n",
    "                     +str(PROTEIN_K)\n",
    "                     +str(RNA_K)\n",
    "                     +'.txt')\n",
    "    arr = ToMatrix(data,'sparse')\n",
    "    [X,Y] = MutualInformationFeatureSelection(arr,data)\n",
    "    [X_train,X_test,Y_train,Y_test] = SplitDataset(X,Y)\n",
    "    [X_train,X_test,Y_train,Y_test] = \\\n",
    "        RandomForestDimensionalityReduction(X_train,X_test,Y_train,Y_test)\n",
    "    DecisionTreePrefit(X_train,X_test,Y_train,Y_test)\n",
    "    LGBFit(X_train,X_test,Y_train,Y_test)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanVariables():\n",
    "    global X,Y\n",
    "    del X,Y\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============RETRIEVE TRIAN DATA=================\n",
      "# DEBUG: # DEBUG: **************new dl 1***************\n",
      "# DEBUG: READ SEQ FROM FILE\n",
      "# DEBUG: READ CLUSTER FROM FILE\n",
      "regex error \n",
      "regex error \n",
      "# DEBUG: READ PAIR FROM FILE\n",
      "# DEBUG: GENERATE NEGATIVE PAIR\n",
      "# DEBUG: negative pair number 2825\n",
      "# DEBUG: PAIR UNION\n",
      "# DEBUG: EXTRACT FEATURES--PROTEIN\n",
      "# DEBUG: EXTRACT FEATURES--RNA\n",
      "# DEBUG: K-MER CALCULATION\n",
      "# DEBUG: FEATURE UNION\n",
      "# DEBUG: GARBAGE COLLECTION\n",
      "MATRIX TRANSFORMATION\n",
      "data shape 5650 7390\n"
     ]
    }
   ],
   "source": [
    "[data,T] = ReadData()\n",
    "[X,Y] = ToMatrix(data,'dense')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_train,X_test,Y_train,Y_test] = SplitDataset(X,Y)\n",
    "[X_train,X_test,Y_train,Y_test] = \\\n",
    "    RandomForestDimensionalityReduction(X_train,X_test,Y_train,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# DecisionTreePrefit(X_train,X_test,Y_train,Y_test)\n",
    "[lgb,cv_results] = LGBFit(X_train,X_test,Y_train,Y_test)\n",
    "WriteResult(DATASET,cv_results,conf,commons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
