{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IDE_Project_Programming\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from module.prepare import *\n",
    "from itertools import product\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "# import redis\n",
    "# import xgboost\n",
    "\n",
    "'''\n",
    "    result = [Ypred,Ytest]\n",
    "'''\n",
    "def scoreFunction(result):\n",
    "    scores = {}\n",
    "\n",
    "    acc = metrics.accuracy_score(result[0],result[1])\n",
    "    \n",
    "    auc = metrics.roc_auc_score(result[0],result[1])\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(result[1], result[0], pos_label=1)\n",
    "    \n",
    "    mcc = metrics.matthews_corrcoef(result[1], result[0])\n",
    "    \n",
    "    tn = sum((result[0]==0) & (result[1]==0))\n",
    "    fp = sum((result[0]==1) & (result[1]==0))\n",
    "    tnr = float(tn)/(fp+tn)\n",
    "    \n",
    "    tp = sum((result[0]==1) & (result[1]==1))\n",
    "    ppv = float(tp)/(tp+fp)\n",
    "    \n",
    "    f_score = metrics.f1_score(result[1], result[0])\n",
    "    \n",
    "    ap = metrics.average_precision_score(result[1], result[0])\n",
    "    \n",
    "    bacc = metrics.balanced_accuracy_score(result[1], result[0])\n",
    "    \n",
    "    brier = metrics.brier_score_loss(result[1], result[0], pos_label=1)\n",
    "    \n",
    "    recall = metrics.recall_score(result[1], result[0])\n",
    "    \n",
    "    scores['acc'] = acc\n",
    "    scores['auc'] = auc\n",
    "    scores['fpr'] = fpr\n",
    "    scores['tpr'] = tpr\n",
    "    scores['mcc'] = mcc\n",
    "    scores['tnr'] = tnr\n",
    "    scores['ppv'] = ppv\n",
    "    scores['f_score'] = f_score\n",
    "    scores['ap'] = ap\n",
    "    scores['brier'] = brier\n",
    "    scores['recall'] = recall\n",
    "    \n",
    "    return scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "    @new_params whether to append new param\n",
    "    @default whether to use default param\n",
    "    @replace whether to replace old param\n",
    "    @tuning whethe to tuning with GridSearchCV\n",
    "    \n",
    "    @return [Ypred,Ytest,score_train,clf]\n",
    "'''\n",
    "def LGBTuning(Xtrain,Xtest,Ytrain,Ytest,new_params=None,default=False,replace=False,tuning=True):\n",
    "    \n",
    "    clf = lgb.LGBMClassifier(objective='cross_entropy', ### {cross_entropy, binary}\n",
    "                             silent=False,\n",
    "                             verbose=1,\n",
    "                             random_state=seed,\n",
    "                             n_jobs=12,\n",
    "#                              class_weight\n",
    "                            )\n",
    "    \n",
    "    gridParams = {\n",
    "        # step 1\n",
    "#     'learning_rate': [0.01,0.05,0.1],\n",
    "#     'boosting_type':['gbdt','goss'],\n",
    "#     'n_estimators': [50,200,500],\n",
    "#     'num_iterations':[200,400,1000],\n",
    "        # step 1 fixed\n",
    "    'learning_rate': [0.1], ### 0.1\n",
    "    'boosting_type':['gbdt'], ### goss>gbdt\n",
    "    'n_estimators': [500],\n",
    "    'num_iterations':[2000], ### 2000\n",
    "#     'max_depth':[6], ### <6\n",
    "        # step 2\n",
    "#     'num_leaves': [200], ### <400<675\n",
    "#     'min_data_in_leaf':[18,20,22], ### 20 default\n",
    "#     'max_bin':[127,255,511],\n",
    "        # step 2 fixed\n",
    "#     'num_leaves': [800],\n",
    "    'max_bin':[256],\n",
    "        # step 3\n",
    "#     'max_depth':[7,8,9,10], ### missed\n",
    "    'colsample_bytree' : [0.9], ### 0.75\n",
    "    'subsample_freq':[1], ### 1\n",
    "        \n",
    "#     'subsample' : [0.7], ### 1\n",
    "#     'min_data_in_leaf':[26],\n",
    "#     'early_stopping_round':[2],\n",
    "#     'reg_alpha' : [1e-3], ### 0\n",
    "#     'reg_lambda' : [0,0.1,0.5], ### 0\n",
    "    }\n",
    "    \n",
    "    if replace is True:\n",
    "        gridParams = {}\n",
    "    if new_params is not None:\n",
    "        gridParams.update(new_params)\n",
    "    \n",
    "\n",
    "    if tuning:\n",
    "        grid = GridSearchCV(clf, gridParams,\n",
    "                        scoring='accuracy',\n",
    "                        verbose=3,\n",
    "                        cv=5,\n",
    "                        n_jobs=1)\n",
    "        print('default params\\n',clf.get_params())\n",
    "        grid.fit(Xtrain,Ytrain)\n",
    "        return grid\n",
    "    else:\n",
    "        if not default:\n",
    "            arg_str = ''\n",
    "            for k,v in gridParams.items():\n",
    "                if type(v[0])==str:\n",
    "                    arg_str += k+'='+\"'\"+v[0]+\"',\"\n",
    "                else:\n",
    "                    arg_str += k+'='+str(v[0])+\",\"\n",
    "            eval(\n",
    "                'clf.'+clf.set_params.__name__+\"(\"\n",
    "                    +arg_str.rstrip(',')+\n",
    "                    \")\"\n",
    "                )\n",
    "#         clf.class_weight = {1:sum(Ytrain==1),0:sum(Ytrain==0)}\n",
    "        print('params\\n',clf.get_params())\n",
    "        clf.fit(Xtrain,Ytrain)\n",
    "        Ypred = clf.predict(Xtest)\n",
    "        score_train = clf.score(Xtrain,Ytrain)\n",
    "        print('train score %f'%score_train)\n",
    "        return [Ypred,Ytest,score_train,clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def LGBFit(X_train,X_test,Y_train,Y_test):\n",
    "    lgb_train = lgb.Dataset(X_train, Y_train)\n",
    "    lgb_test = lgb.Dataset(X_test, Y_test, reference=lgb_train)\n",
    "\n",
    "    params = {    \n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'binary',\n",
    "                'metric': 'roc-auc',\n",
    "#                 'nthread':6,\n",
    "                'learning_rate':0.08,\n",
    "                'num_leaves':300, \n",
    "                'max_depth': -1,   \n",
    "                'subsample': 0.9, \n",
    "                'colsample_bytree': 0.9, \n",
    "#                 'feature_fraction': 1,\n",
    "#                 'bagging_freq': 8,\n",
    "# #                 'num_iterations':300,\n",
    "#                 'min_data_in_leaf':2,\n",
    "#                 'bagging_fraction': 0.8,\n",
    "#                 'num_boost_round':3000,\n",
    "            }\n",
    "\n",
    "    cv_results = lgb.cv(params, lgb_train, nfold=5  \n",
    "                        ,stratified=False, shuffle=True\n",
    "                        ,seed=seed,\n",
    "                        metrics=['auc','binary_logloss','mae']\n",
    "                        ,verbose_eval=1)\n",
    "    print('best n_estimators:', len(cv_results['auc-mean']))\n",
    "    for k,v in cv_results.items():\n",
    "        print('best cv score:', k, pd.Series(cv_results[k]).max())\n",
    "    return [lgb,cv_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "'data_NPInter10412',\n",
    "'reRPI2825',\n",
    "'RPI488',\n",
    "'RPI2241',\n",
    "'RPITER_RPI1807'\n",
    "'''\n",
    "\n",
    "hyper_params = GetConfigure()\n",
    "num_hyper_params = len(hyper_params)\n",
    "lassocv_param = {'threshold':0.05}\n",
    "\n",
    "cv = 5\n",
    "generalize_ratio = 1.0/cv\n",
    "test_ratio = 1.0/cv\n",
    "\n",
    "mi_use = False\n",
    "outside_grid = True\n",
    "tuning_mode = False\n",
    "\n",
    "if tuning_mode:\n",
    "    cv = 1\n",
    "\n",
    "cv_results = []\n",
    "# scores = []\n",
    "'''\n",
    "    topK =3000\n",
    "'''\n",
    "\n",
    "\n",
    "search_param = [{'learning_rate':[0.05,0.1,0.01,0.02],\n",
    "                'colsample_bytree':[0.7,0.8,0.9,1],\n",
    "                 'max_depth':[5,6,7,8,9],\n",
    "                 'num_iterations':[500,1000,2000],\n",
    "#                  'min_data_in_leaf':[20,25,30]\n",
    "                }]\n",
    "search_grid = list(ParameterGrid(search_param))\n",
    "\n",
    "conf_param = {}\n",
    "\n",
    "\n",
    "cfile = GetConfigureObject()\n",
    "commons = dict(cfile.items('common'))\n",
    "\n",
    "# db = redis.StrictRedis(host=commons[str.lower('REDIS_HOST')], port=6379, db=0, \n",
    "#                       password=commons[str.lower('REDIS_PWD')], decode_responses=True\n",
    "#                       )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tuning stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def TuningParametersStage1():\n",
    "    res = []\n",
    "    for DATAID in [0,1,2,3,4]:\n",
    "        INFO('data id %d'%DATAID)\n",
    "        for RNA_K in range(3,7):\n",
    "            for PROTEIN_K in range(3,7):\n",
    "                for TOP_RATIO in np.linspace(0.93,0.99,5):\n",
    "                    [data,T] = ReadData(DATAID,PROTEIN_K,RNA_K)\n",
    "                    [X,Y] = ToMatrix(data,'dense')\n",
    "                    [X_train,X_test,Y_train,Y_test] = SplitDataset(X,Y,generalize_ratio)\n",
    "                    [X_train,X_test,Y_train,Y_test] = \\\n",
    "                                RandomForestDimensionalityReduction(X_train,X_test,Y_train,Y_test,topRatio=0.96)\n",
    "                    r = LGBTuning(X_train,X_test,Y_train,Y_test,tuning=False,default=True)\n",
    "                    r = {'test_score':scoreFunction([r[0],r[1]]),\n",
    "                        'train_score':r[2],\n",
    "                        'RNA_K':RNA_K,\n",
    "                        'PROTEIN_K':PROTEIN_K,\n",
    "                        'TOP_RATIO':TOP_RATIO}\n",
    "                    res.append(r)\n",
    "                    WriteDictResult(DATAID,r,'3-14-result-of-k')\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTuningStage1Result():\n",
    "    fname = './3-14-result-of-k'\n",
    "    with open(fname+'.txt','r+') as f:\n",
    "        text = f.read()\n",
    "        content = text.split('\\n')\n",
    "\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    count = 0\n",
    "    for line in content:\n",
    "        count += 1\n",
    "        if len(line):\n",
    "            if line[0] is '@':\n",
    "                if count>1:\n",
    "                    df = df.append([\n",
    "                        [\n",
    "                           r['DATAID'],\n",
    "                           r['RNA_K'],\n",
    "                           r['PROTEIN_K'],\n",
    "                           r['TOP_RATIO'],\n",
    "                           eval(r['test_score'])['acc'],\n",
    "                           eval(r['test_score'])['auc'],\n",
    "                           r['train_score']\n",
    "                        ]\n",
    "                                   ])\n",
    "                r = {}\n",
    "                r['DATAID'] = line[1]\n",
    "            else:\n",
    "                line = line.split('=\\t')\n",
    "                if line[0] is 'test_score':\n",
    "                    r['test_score'] = dict(eval(line[1]))\n",
    "                else:\n",
    "                    r[line[0]] = line[1]\n",
    "\n",
    "    df.columns=['DATAID','RNA_K','PROTEIN_K',\n",
    "               'TOP_RATIO',\n",
    "               'acc','auc','train_score']\n",
    "    return df\n",
    "df = getTuningStage1Result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tuning stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fname_optimal_stage1 = './3-14-data-param-1.csv'\n",
    "fname_result = './3-18-cv-tune-1.csv'\n",
    "\n",
    "tune_grid = [\n",
    "    [{\n",
    "#         'learning_rate': [0.1], ### 0.1\n",
    "#         'boosting_type':['gbdt'], ### goss>gbdt\n",
    "#         'n_estimators': [500],\n",
    "#         'num_iterations':[1000,2000], ### 2000\n",
    "#         'num_leaves': [200], ### <400<675\n",
    "#         'max_bin':[256],\n",
    "#         'colsample_bytree' : [0.7,0.75,0.8,0.85], ### 0.75\n",
    "#         'subsample_freq':[1], ### 1\n",
    "#         'lambda_l1': [1e-3,0], \n",
    "        'boosting_type': ['gbdt'], \n",
    "        'colsample_bytree': [0.8], \n",
    "        'lambda_l1': [0], \n",
    "        'learning_rate': [0.1], \n",
    "        'max_bin': [256], \n",
    "        'n_estimators': [500], \n",
    "        'num_iterations': [2000], \n",
    "        'num_leaves': [200], \n",
    "        'subsample_freq': [1],\n",
    "    }],\n",
    "    [{\n",
    "#         'colsample_bytree': [1], \n",
    "#         'lambda_l1': [0], \n",
    "#         'learning_rate': [0.05], \n",
    "#         'min_data_in_leaf': [12,13,14,15], \n",
    "#         'num_iterations': [1000], \n",
    "#         'num_leaves': [80,100,120,150,200],\n",
    "        'colsample_bytree': [1], \n",
    "        'lambda_l1': [0], \n",
    "        'learning_rate': [0.05], \n",
    "        'min_data_in_leaf': [14], \n",
    "        'num_iterations': [1000], \n",
    "        'num_leaves': [100],\n",
    "    }],\n",
    "    [{\n",
    "#         'colsample_bytree': [0.7,0.8,0.85,0.9,0.95], \n",
    "#         'lambda_l1': [0], # =\n",
    "#         'learning_rate': [0.05,0.01,0.1], \n",
    "#         'min_data_in_leaf': [20], # =\n",
    "#         'num_iterations': [500,1000,2000],\n",
    "#         'num_leaves': [50],\n",
    "        'colsample_bytree': [0.9], \n",
    "        'lambda_l1': [0], \n",
    "        'learning_rate': [0.05], \n",
    "        'min_data_in_leaf': [18], \n",
    "        'num_iterations': [1000], \n",
    "        'num_leaves': [50],\n",
    "     }],\n",
    "    [{\n",
    "#         'colsample_bytree': [0.8,0.85,0.9,0.95],  \n",
    "#         'lambda_l1': [0.001], \n",
    "#         'learning_rate': [0.1,0.001,0.5],  \n",
    "#         'max_depth': [3,4,6,-1], \n",
    "#         'min_data_in_leaf': [10,18,30], \n",
    "#         'num_iterations': [500,1000,2000], \n",
    "#         'num_leaves': [10,40,60,80,100,120],\n",
    "        'colsample_bytree': [0.9], \n",
    "        'lambda_l1': [0.001], \n",
    "        'learning_rate': [0.5], \n",
    "        'max_depth': [-1], \n",
    "        'min_data_in_leaf': [10], \n",
    "        'num_iterations': [1000], \n",
    "        'num_leaves': [10],\n",
    "     }],\n",
    "    [{\n",
    "#         'colsample_bytree': [0.8,0.85,0.9,0.95],  \n",
    "#         'lambda_l1': [0], \n",
    "#         'learning_rate': [0.01,0.001,0.5], \n",
    "#         'max_depth': [3,4,6,-1],  \n",
    "#         'min_data_in_leaf': [10,18,30], \n",
    "#         'num_iterations': [500,1000,2000], \n",
    "#         'num_leaves': [10,40,60,80,100,120],\n",
    "        'colsample_bytree': [0.95], \n",
    "        'lambda_l1': [0], \n",
    "        'learning_rate': [0.5], \n",
    "        'max_depth': [-1], \n",
    "        'min_data_in_leaf': [10], \n",
    "        'num_iterations': [500], \n",
    "        'num_leaves': [40],\n",
    "     }]\n",
    "]\n",
    "\n",
    "tune_grid = list(map(lambda x:list(ParameterGrid(x)),tune_grid))\n",
    "\n",
    "tuning_cv2 = 10\n",
    "tuning_generalize_ratio2 = 1.0/tuning_cv2\n",
    "df_optimal = pd.read_csv(fname_optimal_stage1)\n",
    "\n",
    "df_columns = ['dataid','cv','training_score','tune_param','acc','auc',\n",
    "              'fpr','tpr','mcc','tnr','ppv','f_score','ap','brier','recall']\n",
    "df_result2 = pd.DataFrame([],columns=df_columns)\n",
    "\n",
    "for _dataid in [0,1,2,3,4]:\n",
    "    INFO('dataid %d'%_dataid)\n",
    "    ### get conf of dataid\n",
    "    df_current = df_optimal.loc[df_optimal['DATAID']==_dataid]\n",
    "    rna_k = df_current['RNA_K'].to_numpy()[0]\n",
    "    protein_k = df_current['PROTEIN_K'].to_numpy()[0]\n",
    "    top_ratio = df_current['TOP_RATIO'].to_numpy()[0]\n",
    "    ### read data\n",
    "    [data,T] = ReadData(_dataid,protein_k,rna_k)\n",
    "    [X,Y] = ToMatrix(data,'dense')\n",
    "    ### split dataset\n",
    "    [X_train,X_test,Y_train,Y_test] = SplitDataset(X,Y,tuning_generalize_ratio2)\n",
    "    ### dimensionality reduction\n",
    "    [X_train,X_test,Y_train,Y_test] = \\\n",
    "                RandomForestDimensionalityReduction(X_train,X_test,Y_train,Y_test,topRatio=top_ratio)\n",
    "    for _cv in range(tuning_cv2):\n",
    "        INFO('tuning cv %d'%_cv)\n",
    "        for sp in tune_grid[_dataid]:\n",
    "            sp = dict(map(lambda x:(x,[sp[x]]),sp))\n",
    "            tune_results = LGBTuning(X_train,X_test,Y_train,Y_test,sp,tuning=False)\n",
    "            tune_score = scoreFunction(tune_results)\n",
    "            r = pd.Series({\n",
    "                            'dataid':_dataid,\n",
    "                            'cv':_cv,\n",
    "                            'training_score':tune_results[2],\n",
    "                            'tune_param':str(sp),\n",
    "                            'acc':tune_score['acc'],\n",
    "                            'auc':tune_score['auc'],\n",
    "                            'fpr':tune_score['fpr'],\n",
    "                            'tpr':tune_score['tpr'],\n",
    "                            'mcc':tune_score['mcc'],\n",
    "                            'tnr':tune_score['tnr'],\n",
    "                            'ppv':tune_score['ppv'],\n",
    "                            'f_score':tune_score['f_score'],\n",
    "                            'ap':tune_score['ap'],\n",
    "                            'brier':tune_score['brier'],\n",
    "                            'recall':tune_score['recall'],\n",
    "            })\n",
    "            df_result2 = df_result2.append(r,ignore_index=True)\n",
    "            \n",
    "df_result2.to_csv(fname_result)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>dataid</th>\n",
       "      <th>cv</th>\n",
       "      <th>training_score</th>\n",
       "      <th>tune_param</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>fpr</th>\n",
       "      <th>tpr</th>\n",
       "      <th>mcc</th>\n",
       "      <th>tnr</th>\n",
       "      <th>ppv</th>\n",
       "      <th>f_score</th>\n",
       "      <th>ap</th>\n",
       "      <th>brier</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.952952</td>\n",
       "      <td>0.953429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.906389</td>\n",
       "      <td>0.936660</td>\n",
       "      <td>0.938605</td>\n",
       "      <td>0.953686</td>\n",
       "      <td>0.925115</td>\n",
       "      <td>0.047048</td>\n",
       "      <td>0.969260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.877876</td>\n",
       "      <td>0.878631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.755902</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>0.867110</td>\n",
       "      <td>0.883249</td>\n",
       "      <td>0.831726</td>\n",
       "      <td>0.122124</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.914966</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.886161</td>\n",
       "      <td>0.885954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.772209</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.895197</td>\n",
       "      <td>0.889371</td>\n",
       "      <td>0.851282</td>\n",
       "      <td>0.113839</td>\n",
       "      <td>0.883621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.987578</td>\n",
       "      <td>0.988206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.974804</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.989011</td>\n",
       "      <td>0.981278</td>\n",
       "      <td>0.012422</td>\n",
       "      <td>0.994475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  dataid  cv  training_score tune_param       acc       auc  \\\n",
       "49         NaN       0 NaN             NaN        NaN  0.952952  0.953429   \n",
       "49         NaN       1 NaN             NaN        NaN  0.877876  0.878631   \n",
       "49         NaN       2 NaN             NaN        NaN  0.918367  0.931034   \n",
       "49         NaN       3 NaN             NaN        NaN  0.886161  0.885954   \n",
       "49         NaN       4 NaN             NaN        NaN  0.987578  0.988206   \n",
       "\n",
       "    fpr  tpr       mcc       tnr       ppv   f_score        ap     brier  \\\n",
       "49  NaN  NaN  0.906389  0.936660  0.938605  0.953686  0.925115  0.047048   \n",
       "49  NaN  NaN  0.755902  0.854545  0.867110  0.883249  0.831726  0.122124   \n",
       "49  NaN  NaN  0.847579  1.000000  1.000000  0.909091  0.914966  0.081633   \n",
       "49  NaN  NaN  0.772209  0.888889  0.895197  0.889371  0.851282  0.113839   \n",
       "49  NaN  NaN  0.974804  0.978723  0.983607  0.989011  0.981278  0.012422   \n",
       "\n",
       "      recall  \n",
       "49  0.969260  \n",
       "49  0.900000  \n",
       "49  0.833333  \n",
       "49  0.883621  \n",
       "49  0.994475  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./3-18-cv-tune-1.csv')\n",
    "keys = ['acc','auc','mcc','tnr','ppv','f_score','ap','brier','recall']\n",
    "key_by = 'dataid'\n",
    "\n",
    "indexes = []\n",
    "indexes.extend(keys)\n",
    "indexes.append(key_by)\n",
    "\n",
    "key_agg = dict(map(lambda x:(x,np.mean),keys))\n",
    "\n",
    "# print(df)\n",
    "\n",
    "df_temp = df.groupby(by=[key_by]) \\\n",
    "                .aggregate(key_agg).reset_index()\n",
    "\n",
    "df_result = df.join(df_temp.set_index(indexes),on=indexes,how='right')\n",
    "\n",
    "df_result\n",
    "# df_result.to_csv('./3-17-param-tune-4-result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv result processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./3-18-cv-tune-1.csv')\n",
    "key = 'auc'\n",
    "key_by = 'dataid'\n",
    "df_temp = df.groupby(by=[key_by]) \\\n",
    "                .aggregate({key:np.mean}).reset_index()\n",
    "\n",
    "df_result = df.join(df_temp.set_index([key_by,key]),on=[key_by,key],how='inner')\n",
    "\n",
    "df_result\n",
    "df_result.to_csv('./3-18-cv-tune-result-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['DATAID']=='0')\n",
    "      & (df['RNA_K']=='3')\n",
    "      & ( (df['PROTEIN_K']=='3') | (df['PROTEIN_K']=='4') )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "for batch in range(cv):\n",
    "    INFO('cross validation batch %d'%batch)\n",
    "    if mi_use==True:\n",
    "        arr = ToMatrix(data,'sparse')\n",
    "        [X_train,X_test,Y_train,Y_test] = MutualInformationFeatureSelection2(arr,data,generalize_ratio)\n",
    "        [X_train,X_test,Y_train,Y_test] = \\\n",
    "            RandomForestDimensionalityReduction(X_train,X_test,Y_train,Y_test)\n",
    "    else:\n",
    "        [X,Y] = ToMatrix(data,'dense')\n",
    "        [X_train,X_test,Y_train,Y_test] = SplitDataset(X,Y,generalize_ratio)\n",
    "#         X_train,X_test,Y_train,Y_test = IsomapDimensionalityReduction(X_train,X_test,Y_train,Y_test)\n",
    "#         [X_train,X_test,Y_train,Y_test] = LassoCVFeatureSelection(X_train,X_test,Y_train,Y_test,lassocv_param)\n",
    "        [X_train,X_test,Y_train,Y_test] = \\\n",
    "            RandomForestDimensionalityReduction(X_train,X_test,Y_train,Y_test)\n",
    "#         [X_train,X_test,Y_train,Y_test] = \\\n",
    "#             PCADimensionalityReduction(X_train,X_test,Y_train,Y_test)\n",
    "    if tuning_mode:\n",
    "        [Xtrain,Ytrain] = merge_train_test(X_train,X_test,Y_train,Y_test)\n",
    "        grid = LGBTuning(Xtrain,[],Ytrain,[],True)\n",
    "        cv_results.append(grid)\n",
    "        break\n",
    "    else:\n",
    "        if outside_grid is True:\n",
    "            for sp in search_grid:\n",
    "                sp = dict(map(lambda x:(x,[sp[x]]),sp))\n",
    "                tune_results = LGBTuning(X_train,X_test,Y_train,Y_test,sp,tuning=False)\n",
    "                r = {'batch':batch,'res':tune_results,'sp':sp,'score':scoreFunction(tune_results)}\n",
    "                cv_results.append(r)\n",
    "            break\n",
    "        else:\n",
    "            tune_results = LGBTuning(X_train,X_test,Y_train,Y_test,tuning=False,default=False)\n",
    "            r = {'batch':batch,'res':tune_results,'score':scoreFunction(tune_results)}\n",
    "            cv_results.append(r)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### compute scores\n",
    "scores = [scoreFunction(r['res'])for r in cv_results]\n",
    "auc = np.mean([x['auc'] for x in scores])\n",
    "acc = np.mean([x['acc'] for x in scores])\n",
    "scores,auc,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### save model\n",
    "if outside_grid is True:\n",
    "    search_param = set( list(map(lambda x:x['sp'],cv_results)) )\n",
    "    scores = [{sp:[] for sp in search_param}]\n",
    "    for sp in search_param:\n",
    "        scores[sp] = np.mean(list( map(lambda x:x['score'],filter(lambda x:x['sp']==sp,cv_results)) ))\n",
    "    best_sp = sorted(scores,key=lambda x:scores[x][0],reverse=True)[0]['sp']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data 3 6\n",
      "=============RETRIEVE TRIAN DATA=================\n",
      "# DEBUG: # DEBUG: **************new dl 1***************\n",
      "# DEBUG: READ SEQ FROM FILE\n",
      "# DEBUG: READ CLUSTER FROM FILE\n",
      "regex error \n",
      "regex error \n",
      "# DEBUG: READ PAIR FROM FILE\n",
      "# DEBUG: GENERATE NEGATIVE PAIR\n",
      "# DEBUG: negative pair number 2825\n",
      "INFO::count of negative pairs2825\n",
      "# DEBUG: PAIR UNION\n",
      "# DEBUG: EXTRACT FEATURES--PROTEIN\n",
      "# DEBUG: EXTRACT FEATURES--RNA\n",
      "# DEBUG: K-MER CALCULATION\n",
      "# DEBUG: FEATURE UNION\n",
      "# DEBUG: GARBAGE COLLECTION\n",
      "MATRIX TRANSFORMATION\n",
      "data shape 5650 6183\n",
      "rf raw data fit score 0.998009\n",
      "INFO::dimension remained 6057 0.960000\n",
      "dimension remained 6057\n",
      "params\n",
      " {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': 12, 'num_leaves': 31, 'objective': 'cross_entropy', 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': False, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'verbose': 1}\n",
      "train score 0.946681\n"
     ]
    }
   ],
   "source": [
    "DATAID = 1\n",
    "PROTEIN_K = 3\n",
    "RNA_K = 6\n",
    "topRatio = 0.99\n",
    "[data,T] = ReadData(DATAID,PROTEIN_K,RNA_K)\n",
    "[X,Y] = ToMatrix(data,'dense')\n",
    "[X_train,X_test,Y_train,Y_test] = SplitDataset(X,Y,generalize_ratio)\n",
    "[X_train,X_test,Y_train,Y_test] = \\\n",
    "    RandomForestDimensionalityReduction(X_train,X_test,Y_train,Y_test,topRatio=0.96)\n",
    "r1 = LGBTuning(X_train,X_test,Y_train,Y_test,tuning=False,default=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('cb', cb.CatBoostClassifier(verbose=0)),\n",
    "    ('lgb', lgb.LGBMClassifier(objective='cross_entropy', ### {cross_entropy, binary}\n",
    "                             silent=False,\n",
    "                             verbose=1,\n",
    "                             random_state=seed,\n",
    "                             n_jobs=12,\n",
    "                            )),\n",
    "    ('xgb',xgb.XGBClassifier()),\n",
    "]\n",
    "clf = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegressionCV()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train,Y_train).score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.8389380530973451,\n",
       " 'auc': 0.8389386852303808,\n",
       " 'fpr': array([0.        , 0.15817223, 1.        ]),\n",
       " 'tpr': array([0.        , 0.83600713, 1.        ]),\n",
       " 'mcc': 0.6778561339671516,\n",
       " 'tnr': 0.8418277680140598,\n",
       " 'ppv': 0.8389982110912343,\n",
       " 'f_score': 0.8375,\n",
       " 'ap': 0.7828244158377446,\n",
       " 'brier': 0.16106194690265488,\n",
       " 'recall': 0.8360071301247772}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoreFunction([r1[0],r1[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "# clf_xgb = xgb.XGBClassifier()\n",
    "# clf_xgb.fit(X_train,Y_train).score(X_test,Y_test)\n",
    "clf_cb = cb.CatBoostClassifier()\n",
    "clf_cb.fit(X_train,Y_train).score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [score for grid in cv_results for score in grid.cv_results_['mean_test_score']]\n",
    "sns.distplot(scores,rug=True,bins=20)\n",
    "plt.show()\n",
    "\n",
    "# param_rank = np.array([grid.cv_results_['mean_test_score'],grid.cv_results_['params']]).T\n",
    "# a = sorted(param_rank,key=lambda x:x[0],reverse=True)\n",
    "# a = np.array(list(a))\n",
    "\n",
    "# a\n",
    "max( cv_results,key=lambda x:np.mean(x.cv_results_['mean_test_score']) ).best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = list( sorted(grid.best_estimator_.feature_importances_,reverse=True) )\n",
    "sum(feature_importance[:2000])/sum(feature_importance)\n",
    "\n",
    "plt.figure()\n",
    "sns.distplot(grid.best_estimator_.feature_importances_,bins=100)\n",
    "plt.xlabel('feature importance')\n",
    "plt.ylabel('ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
